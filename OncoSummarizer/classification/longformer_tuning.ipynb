{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate --upgrade"
      ],
      "metadata": {
        "id": "87dnj2XPQ093"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "ZoMaydHWLKHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlzN4OViS3Wk"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# Longformer Fine-Tuned (BlueScrubs) ‚Äî F1-Optimized Version (compatible API)\n",
        "# =====================================\n",
        "\n",
        "# (Optional) Install/refresh deps; if this errors, it's fine as long as imports work\n",
        "!pip -q install datasets accelerate evaluate matplotlib\n",
        "# If transformers install fails or is skipped, Colab's preinstalled version will be used.\n",
        "\n",
        "# ==== Disable external loggers (W&B, Hugging Face telemetry)\n",
        "import os, gc, torch\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "\n",
        "# ==== Clean GPU memory before starting\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ==== Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    AutoConfig,\n",
        ")\n",
        "import evaluate\n",
        "import transformers as hf\n",
        "\n",
        "print(\"‚úÖ Setup complete.\")\n",
        "print(\"üî¢ transformers version:\", hf.__version__)\n",
        "print(\"üíª GPU available:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# ==== (Recommended) remove old tuned checkpoints to avoid resume/max_steps issues\n",
        "!rm -rf longformer_bluescrubs_tuned\n",
        "\n",
        "# ==== Paths\n",
        "TRAIN = \"./bluescrubs_train_chunked_longformer.csv\"\n",
        "VAL   = \"./bluescrubs_val_chunked_longformer.csv\"\n",
        "TEST  = \"./bluescrubs_test_chunked_longformer.csv\"\n",
        "\n",
        "# ==== Convert CSVs to Hugging Face Datasets\n",
        "def to_hfds(path):\n",
        "    df = pd.read_csv(path)\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    return Dataset.from_pandas(df[[\"text\", \"label\"]])\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": to_hfds(TRAIN),\n",
        "    \"validation\": to_hfds(VAL),\n",
        "    \"test\": to_hfds(TEST)\n",
        "})\n",
        "\n",
        "# ==== Tokenization (with labels preserved)\n",
        "MODEL_NAME = \"allenai/longformer-base-4096\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "def preprocess(batch):\n",
        "    enc = tokenizer(batch[\"text\"], truncation=True, max_length=4096)\n",
        "    enc[\"labels\"] = batch[\"label\"]\n",
        "    return enc\n",
        "\n",
        "print(\"üîÑ Tokenizing datasets...\")\n",
        "tokenized = ds.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
        "print(\"‚úÖ Tokenization complete. Columns now:\", tokenized[\"train\"].column_names)\n",
        "\n",
        "# ==== Model\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
        "print(\"‚úÖ Model loaded successfully on\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# (Optional) gradient checkpointing for memory\n",
        "if hasattr(model, \"gradient_checkpointing_enable\"):\n",
        "    model.gradient_checkpointing_enable()\n",
        "    print(\"üß† Gradient checkpointing enabled.\")\n",
        "\n",
        "# ==== Metrics\n",
        "accuracy  = evaluate.load(\"accuracy\")\n",
        "f1        = evaluate.load(\"f1\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall    = evaluate.load(\"recall\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\":  accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"binary\")[\"precision\"],\n",
        "        \"recall\":    recall.compute(predictions=preds, references=labels, average=\"binary\")[\"recall\"],\n",
        "        \"f1\":        f1.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"],\n",
        "    }\n",
        "\n",
        "# ==== Training Arguments (TUNED) ‚Äî use eval_strategy (old API)\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./longformer_bluescrubs_tuned\",\n",
        "\n",
        "    eval_strategy=\"steps\",        # üëà older name, works with your version\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",   # select best checkpoint by F1\n",
        "    greater_is_better=True,\n",
        "\n",
        "    learning_rate=1e-5,\n",
        "    warmup_ratio=0.1,             # if this errors, you can comment it out\n",
        "    lr_scheduler_type=\"cosine\",   # same here; both usually supported\n",
        "\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "\n",
        "    num_train_epochs=3,           # longer than baseline\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "\n",
        "    dataloader_num_workers=0,\n",
        "    logging_steps=100,\n",
        "    report_to=[],                 # disable W&B\n",
        "\n",
        "    overwrite_output_dir=True,\n",
        "    max_steps=-1                  # rely on epochs, not a fixed step cap\n",
        ")\n",
        "\n",
        "# ==== Trainer (no early stopping; simple & robust)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# ==== Train (fresh run)\n",
        "print(\"üöÄ Starting fine-tuning...\")\n",
        "train_result = trainer.train(resume_from_checkpoint=False)\n",
        "print(\"‚úÖ Training finished.\")\n",
        "\n",
        "# ==== Evaluate on Test Set with BEST model (by F1)\n",
        "print(\"\\nüß™ Evaluating on test set with BEST checkpoint...\")\n",
        "test_results = trainer.evaluate(tokenized[\"test\"], metric_key_prefix=\"test\")\n",
        "print(\"\\n===== TEST RESULTS (TUNED MODEL) =====\")\n",
        "for k, v in test_results.items():\n",
        "    try:\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "    except TypeError:\n",
        "        print(f\"{k}: {v}\")\n",
        "\n",
        "# ==== Plot Training & Validation Loss\n",
        "log_history = pd.DataFrame(trainer.state.log_history)\n",
        "train_loss = log_history[log_history[\"loss\"].notna()]\n",
        "eval_metrics = log_history[log_history[\"eval_loss\"].notna()]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_loss[\"step\"], train_loss[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(eval_metrics[\"step\"], eval_metrics[\"eval_loss\"], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Longformer Fine-Tuned: Training vs Validation Loss\")\n",
        "plt.show()\n",
        "\n",
        "# ==== Save results\n",
        "pd.DataFrame([test_results]).to_csv(\"longformer_tuned_results.csv\", index=False)\n",
        "log_history.to_csv(\"longformer_tuned_training_log.csv\", index=False)\n",
        "print(\"\\n‚úÖ Saved tuned test results to longformer_tuned_results.csv and training log to longformer_tuned_training_log.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Where to export this tuned model in Colab\n",
        "LONGFORMER_EXPORT_DIR = \"/content/longformer_oncosummarizer_tuned\"\n",
        "Path(LONGFORMER_EXPORT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Because load_best_model_at_end=True, trainer.model is already the BEST checkpoint (by F1)\n",
        "best_model = trainer.model\n",
        "\n",
        "best_model.save_pretrained(LONGFORMER_EXPORT_DIR)\n",
        "tokenizer.save_pretrained(LONGFORMER_EXPORT_DIR)\n",
        "\n",
        "print(\"üìÅ Saved tuned Longformer model to:\", LONGFORMER_EXPORT_DIR)\n",
        "!ls -la \"$LONGFORMER_EXPORT_DIR\"\n"
      ],
      "metadata": {
        "id": "MIxpQjkRcvPI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}