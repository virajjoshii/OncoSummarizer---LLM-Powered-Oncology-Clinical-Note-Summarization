{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qItYiqnr1zV0"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# Longformer Baseline (BlueScrubs) â€” FINAL STABLE A100 VERSION\n",
        "# =====================================\n",
        "\n",
        "!pip -q install transformers==4.46.3 datasets accelerate evaluate matplotlib torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# ==== Disable external loggers (W&B, Hugging Face telemetry)\n",
        "import os, gc, torch\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "\n",
        "# ==== Clean GPU memory before starting\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ==== Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    AutoConfig\n",
        ")\n",
        "import evaluate\n",
        "\n",
        "print(\"âœ… Setup complete. GPU available:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# ==== Paths\n",
        "TRAIN = \"./bluescrubs_train_chunked_longformer.csv\"\n",
        "VAL   = \"./bluescrubs_val_chunked_longformer.csv\"\n",
        "TEST  = \"./bluescrubs_test_chunked_longformer.csv\"\n",
        "\n",
        "# ==== Convert CSVs to Hugging Face Datasets\n",
        "def to_hfds(path):\n",
        "    df = pd.read_csv(path)\n",
        "    df[\"label\"] = df[\"label\"].astype(int)\n",
        "    return Dataset.from_pandas(df[[\"text\", \"label\"]])\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": to_hfds(TRAIN),\n",
        "    \"validation\": to_hfds(VAL),\n",
        "    \"test\": to_hfds(TEST)\n",
        "})\n",
        "\n",
        "# ==== Tokenization (with labels preserved)\n",
        "MODEL_NAME = \"allenai/longformer-base-4096\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "\n",
        "def preprocess(batch):\n",
        "    enc = tokenizer(batch[\"text\"], truncation=True, max_length=4096)\n",
        "    enc[\"labels\"] = batch[\"label\"]\n",
        "    return enc\n",
        "\n",
        "print(\"ðŸ”„ Tokenizing datasets...\")\n",
        "tokenized = ds.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
        "print(\"âœ… Tokenization complete. Columns now:\", tokenized[\"train\"].column_names)\n",
        "\n",
        "# ==== Model\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
        "print(\"âœ… Model loaded successfully on\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# ==== Metrics\n",
        "accuracy  = evaluate.load(\"accuracy\")\n",
        "f1        = evaluate.load(\"f1\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall    = evaluate.load(\"recall\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\":  accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"binary\")[\"precision\"],\n",
        "        \"recall\":    recall.compute(predictions=preds, references=labels, average=\"binary\")[\"recall\"],\n",
        "        \"f1\":        f1.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"],\n",
        "    }\n",
        "\n",
        "# ==== Training Arguments (Fixed to match save/eval strategy)\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./longformer_bluescrubs_baseline\",\n",
        "    eval_strategy=\"steps\",              # evaluate periodically\n",
        "    eval_steps=1000,                    # every 1000 steps\n",
        "    save_strategy=\"steps\",              # âœ… match strategy\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,        # works fine now\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    dataloader_num_workers=0,\n",
        "    logging_steps=100,\n",
        "    report_to=[]                        # disable W&B\n",
        ")\n",
        "\n",
        "# ==== Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# ==== Train (first run â€” no checkpoint yet)\n",
        "print(\"ðŸš€ Starting training...\")\n",
        "trainer.train()  # changed from resume_from_checkpoint=True â†’ clean start\n",
        "\n",
        "# ==== Evaluate on Test Set\n",
        "print(\"\\nðŸ§ª Evaluating on test set...\")\n",
        "test_results = trainer.evaluate(tokenized[\"test\"], metric_key_prefix=\"test\")\n",
        "print(\"\\n===== TEST RESULTS =====\")\n",
        "for k, v in test_results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# ==== Plot Training & Validation Loss\n",
        "log_history = pd.DataFrame(trainer.state.log_history)\n",
        "train_loss = log_history[log_history[\"loss\"].notna()]\n",
        "eval_metrics = log_history[log_history[\"eval_loss\"].notna()]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_loss[\"step\"], train_loss[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(eval_metrics[\"step\"], eval_metrics[\"eval_loss\"], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Longformer Baseline: Training vs Validation Loss\")\n",
        "plt.show()\n",
        "\n",
        "# ==== Save results\n",
        "pd.DataFrame([test_results]).to_csv(\"longformer_results.csv\", index=False)\n",
        "log_history.to_csv(\"longformer_training_log.csv\", index=False)\n",
        "print(\"\\nâœ… Saved test results to longformer_results.csv and training log to longformer_training_log.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers tokenizers simpletransformers\n",
        "!pip install -U --force-reinstall transformers==4.46.3 datasets evaluate accelerate\n"
      ],
      "metadata": {
        "id": "oL76mdNa4bwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers, inspect\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "print(\"TrainingArguments file path:\", inspect.getfile(TrainingArguments))\n"
      ],
      "metadata": {
        "id": "0EKHenRw95KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./test_dir\",\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Works fine now!\")\n"
      ],
      "metadata": {
        "id": "NdHmIxDY7JPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "kznPLNLJ_VIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers==4.46.3 datasets evaluate accelerate matplotlib\n"
      ],
      "metadata": {
        "id": "BVOpuKPj_zH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "_4CJqED01_6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}