{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n"
      ],
      "metadata": {
        "id": "vbHnAoXU0Wsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers==4.46.3 evaluate==0.4.2 rouge_score==0.1.2\n"
      ],
      "metadata": {
        "id": "KNsHBulz0ltN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers, evaluate\n",
        "print(\"Transformers:\", transformers.__version__)   # should print 4.46.3\n",
        "print(\"Evaluate:\", evaluate.__version__)           # should print 0.4.2\n"
      ],
      "metadata": {
        "id": "YhZs6Y1Y1UeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbViFzLWMePq"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# ROND ‚Üí BART Fine-tuning (Summarization) ‚Äî FIXED VERSION\n",
        "# =========================\n",
        "\n",
        "# (Colab) Installs\n",
        "!pip -q install transformers==4.46.3 datasets evaluate accelerate sentencepiece rouge_score\n",
        "\n",
        "# ---- Setup\n",
        "import os, numpy as np, pandas as pd, torch\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"          # no wandb\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"   # quieter logs\n",
        "SEED = 42\n",
        "\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    EarlyStoppingCallback,\n",
        "    set_seed\n",
        ")\n",
        "import evaluate\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "# ---- Paths (use your processed CSVs)\n",
        "TRAIN = \"./rond_train_processed.csv\"\n",
        "VAL   = \"./rond_val_processed.csv\"\n",
        "TEST  = \"./rond_test_processed.csv\"\n",
        "\n",
        "# ---- Load CSVs ‚Üí HF Datasets\n",
        "def load_split(path):\n",
        "    df = pd.read_csv(path)\n",
        "    # Build a single \"source\" field (instruction + input if present)\n",
        "    if \"instruction\" in df.columns:\n",
        "        df[\"source\"] = \"Instruction: \" + df[\"instruction\"].astype(str) + \"\\nInput: \" + df[\"input\"].astype(str)\n",
        "    else:\n",
        "        df[\"source\"] = df[\"input\"].astype(str)\n",
        "    df = df[[\"source\", \"output\"]].rename(columns={\"output\": \"target\"})\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": load_split(TRAIN),\n",
        "    \"validation\": load_split(VAL),\n",
        "    \"test\": load_split(TEST)\n",
        "})\n",
        "\n",
        "# ---- Model & Tokenizer\n",
        "MODEL_NAME = \"facebook/bart-base\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model      = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# üîß Set generation behaviour on the model config\n",
        "gen_cfg = model.generation_config\n",
        "gen_cfg.max_length = 128\n",
        "gen_cfg.num_beams = 4\n",
        "gen_cfg.no_repeat_ngram_size = 3\n",
        "model.generation_config = gen_cfg\n",
        "\n",
        "# ---- Tokenization\n",
        "max_source_len = 512\n",
        "max_target_len = 128\n",
        "\n",
        "def preprocess(ex):\n",
        "    model_in = tokenizer(\n",
        "        ex[\"source\"],\n",
        "        max_length=max_source_len,\n",
        "        truncation=True\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            ex[\"target\"],\n",
        "            max_length=max_target_len,\n",
        "            truncation=True\n",
        "        )\n",
        "    model_in[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_in\n",
        "\n",
        "tokenized = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n",
        "collator  = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# ---- Metrics (ROUGE, computed on generated text)\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds  = [p.strip() for p in preds]\n",
        "    labels = [l.strip() for l in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    if isinstance(preds, tuple):  # some versions return (logits, ...)\n",
        "        preds = preds[0]\n",
        "\n",
        "    # Replace -100 with pad_token_id so we can decode labels\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "    return {\n",
        "        \"rouge1\": result[\"rouge1\"],\n",
        "        \"rouge2\": result[\"rouge2\"],\n",
        "        \"rougeL\": result[\"rougeL\"]\n",
        "    }\n",
        "\n",
        "# ---- Training Args (fine-tune settings, cleaned)\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./bart_rond_fixed_run\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rougeL\",\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # üîß Hyperparameters (closer to baseline)\n",
        "    learning_rate=5e-5,              # back to baseline LR\n",
        "    num_train_epochs=3,              # a bit longer than 2, but not crazy\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.03,               # small warmup\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    label_smoothing_factor=0.0,      # turn off smoothing for now\n",
        "    fp16=True,\n",
        "\n",
        "    predict_with_generate=True,      # still evaluate on generated summaries\n",
        "    logging_steps=100,\n",
        "    report_to=[],\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# ---- Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")\n",
        "\n",
        "# ---- Train\n",
        "print(\"üöÄ Fine-tuning BART on ROND (fixed script)...\")\n",
        "trainer.train()\n",
        "\n",
        "# ---- Evaluate & Generate on TEST\n",
        "print(\"üß™ Generating test summaries & computing ROUGE...\")\n",
        "test_out = trainer.predict(tokenized[\"test\"], metric_key_prefix=\"test\")\n",
        "print(\"‚úÖ Test metrics:\", {k: float(v) for k, v in test_out.metrics.items() if k.startswith(\"test_\")})\n",
        "\n",
        "# Decode predictions + references and save a CSV\n",
        "pred_ids = test_out.predictions\n",
        "if isinstance(pred_ids, tuple):\n",
        "    pred_ids = pred_ids[0]\n",
        "decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "# Rebuild refs from original test split to save a nice CSV\n",
        "raw_test = ds[\"test\"].to_pandas()\n",
        "out_df = pd.DataFrame({\n",
        "    \"instruction\": raw_test[\"source\"].str.extract(r\"Instruction:\\s*(.*)\\n\", expand=False),\n",
        "    \"input_text\":  raw_test[\"source\"],\n",
        "    \"reference_summary\": raw_test[\"target\"],\n",
        "    \"predicted_summary\": decoded_preds\n",
        "})\n",
        "out_df.to_csv(\"rond_predictions_fixed.csv\", index=False)\n",
        "print(\"üíæ Saved test summaries ‚Üí rond_predictions_fixed.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BART on ROND ‚Äì LR = 1e-5 ====\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch\n",
        "\n",
        "# ==== Paths (ROND: no chunking) ====\n",
        "TRAIN = \"./rond_train_processed.csv\"\n",
        "VAL   = \"./rond_val_processed.csv\"\n",
        "TEST  = \"./rond_test_processed.csv\"\n",
        "\n",
        "# ==== Load CSVs ‚Üí HuggingFace Datasets ====\n",
        "def load_split(path):\n",
        "    df = pd.read_csv(path)\n",
        "    if \"instruction\" in df.columns:\n",
        "        df[\"source\"] = \"Instruction: \" + df[\"instruction\"].astype(str) + \"\\nInput: \" + df[\"input\"].astype(str)\n",
        "    else:\n",
        "        df[\"source\"] = df[\"input\"].astype(str)\n",
        "    df = df[[\"source\", \"output\"]].rename(columns={\"output\": \"target\"})\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": load_split(TRAIN),\n",
        "    \"validation\": load_split(VAL),\n",
        "    \"test\": load_split(TEST)\n",
        "})\n",
        "\n",
        "# ==== Model & Tokenizer ====\n",
        "MODEL_NAME = \"facebook/bart-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "max_source_len = 512\n",
        "max_target_len = 128\n",
        "\n",
        "def preprocess(batch):\n",
        "    model_in = tokenizer(batch[\"source\"], max_length=max_source_len, truncation=True)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"target\"], max_length=max_target_len, truncation=True)\n",
        "    model_in[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_in\n",
        "\n",
        "tokenized = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n",
        "collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# ==== Metrics (ROUGE-L) ====\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "\n",
        "    # Handle tuple outputs and logits ‚Üí token IDs\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    if isinstance(preds, np.ndarray) and preds.ndim == 3:\n",
        "        preds = np.argmax(preds, axis=-1)  # convert logits ‚Üí token IDs\n",
        "\n",
        "    # Convert torch tensors ‚Üí numpy\n",
        "    if isinstance(preds, torch.Tensor):\n",
        "        preds = preds.cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "    # Replace -100 (ignored tokens) with pad_token_id\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    return {\"rougeL\": scores[\"rougeL\"]}\n",
        "\n",
        "# ==== TrainingArguments (LR = 1e-5) ====\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bart_rond_lr1e-5\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,          # üîπ changed\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs_lr1e-5\",\n",
        "    logging_steps=100,\n",
        "    report_to=[],\n",
        "    disable_tqdm=False,\n",
        ")\n",
        "\n",
        "# ==== Trainer ====\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"üöÄ Training started (LR=1e-5)...\\n\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nüîç Evaluating on test set (LR=1e-5)...\\n\")\n",
        "test_metrics = trainer.evaluate(tokenized[\"test\"], metric_key_prefix=\"test\")\n",
        "print(\"‚úÖ Test set metrics (LR=1e-5):\", test_metrics)\n"
      ],
      "metadata": {
        "id": "hXOz47HTD-UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BART on ROND ‚Äì LR = 3e-5 ====\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch\n",
        "\n",
        "TRAIN = \"./rond_train_processed.csv\"\n",
        "VAL   = \"./rond_val_processed.csv\"\n",
        "TEST  = \"./rond_test_processed.csv\"\n",
        "\n",
        "def load_split(path):\n",
        "    df = pd.read_csv(path)\n",
        "    if \"instruction\" in df.columns:\n",
        "        df[\"source\"] = \"Instruction: \" + df[\"instruction\"].astype(str) + \"\\nInput: \" + df[\"input\"].astype(str)\n",
        "    else:\n",
        "        df[\"source\"] = df[\"input\"].astype(str)\n",
        "    df = df[[\"source\", \"output\"]].rename(columns={\"output\": \"target\"})\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": load_split(TRAIN),\n",
        "    \"validation\": load_split(VAL),\n",
        "    \"test\": load_split(TEST)\n",
        "})\n",
        "\n",
        "MODEL_NAME = \"facebook/bart-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "max_source_len = 512\n",
        "max_target_len = 128\n",
        "\n",
        "def preprocess(batch):\n",
        "    model_in = tokenizer(batch[\"source\"], max_length=max_source_len, truncation=True)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"target\"], max_length=max_target_len, truncation=True)\n",
        "    model_in[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_in\n",
        "\n",
        "tokenized = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n",
        "collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    if isinstance(preds, np.ndarray) and preds.ndim == 3:\n",
        "        preds = np.argmax(preds, axis=-1)\n",
        "    if isinstance(preds, torch.Tensor):\n",
        "        preds = preds.cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    return {\"rougeL\": scores[\"rougeL\"]}\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bart_rond_lr3e-5\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,          # üîπ changed\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs_lr3e-5\",\n",
        "    logging_steps=100,\n",
        "    report_to=[],\n",
        "    disable_tqdm=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"üöÄ Training started (LR=3e-5)...\\n\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nüîç Evaluating on test set (LR=3e-5)...\\n\")\n",
        "test_metrics = trainer.evaluate(tokenized[\"test\"], metric_key_prefix=\"test\")\n",
        "print(\"‚úÖ Test set metrics (LR=3e-5):\", test_metrics)\n"
      ],
      "metadata": {
        "id": "HJyalVhUEHxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BART on ROND ‚Äì LR = 5e-5 (baseline) ====\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import torch\n",
        "\n",
        "TRAIN = \"./rond_train_processed.csv\"\n",
        "VAL   = \"./rond_val_processed.csv\"\n",
        "TEST  = \"./rond_test_processed.csv\"\n",
        "\n",
        "def load_split(path):\n",
        "    df = pd.read_csv(path)\n",
        "    if \"instruction\" in df.columns:\n",
        "        df[\"source\"] = \"Instruction: \" + df[\"instruction\"].astype(str) + \"\\nInput: \" + df[\"input\"].astype(str)\n",
        "    else:\n",
        "        df[\"source\"] = df[\"input\"].astype(str)\n",
        "    df = df[[\"source\", \"output\"]].rename(columns={\"output\": \"target\"})\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": load_split(TRAIN),\n",
        "    \"validation\": load_split(VAL),\n",
        "    \"test\": load_split(TEST)\n",
        "})\n",
        "\n",
        "MODEL_NAME = \"facebook/bart-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "max_source_len = 512\n",
        "max_target_len = 128\n",
        "\n",
        "def preprocess(batch):\n",
        "    model_in = tokenizer(batch[\"source\"], max_length=max_source_len, truncation=True)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"target\"], max_length=max_target_len, truncation=True)\n",
        "    model_in[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_in\n",
        "\n",
        "tokenized = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n",
        "collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    if isinstance(preds, np.ndarray) and preds.ndim == 3:\n",
        "        preds = np.argmax(preds, axis=-1)\n",
        "    if isinstance(preds, torch.Tensor):\n",
        "        preds = preds.cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    return {\"rougeL\": scores[\"rougeL\"]}\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bart_rond_lr5e-5\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,          # üîπ baseline\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs_lr5e-5\",\n",
        "    logging_steps=100,\n",
        "    report_to=[],\n",
        "    disable_tqdm=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"üöÄ Training started (LR=5e-5)...\\n\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nüîç Evaluating on test set (LR=5e-5)...\\n\")\n",
        "test_metrics = trainer.evaluate(tokenized[\"test\"], metric_key_prefix=\"test\")\n",
        "print(\"‚úÖ Test set metrics (LR=5e-5):\", test_metrics)\n"
      ],
      "metadata": {
        "id": "Ak_hqmTAEV68"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}