{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUj1Wf2tXbRl"
      },
      "outputs": [],
      "source": [
        "!pip -q install reportlab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports, paths, helpers"
      ],
      "metadata": {
        "id": "HTbOE1bbpU-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, textwrap, random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Where your files live in Colab’s sidebar (adjust if needed)\n",
        "ROND_FILES = [\"./ROND_train.csv\",\"./ROND_val.csv\",\"./ROND_test.csv\"]\n",
        "BLUESCRUBS_FILES = [\"./bluescrubs_train_clean.csv\",\"./bluescrubs_val_clean.csv\",\"./bluescrubs_test_clean.csv\"]\n",
        "\n",
        "PLOT_DIR = \"./eda_figs\"\n",
        "os.makedirs(PLOT_DIR, exist_ok=True)\n",
        "\n",
        "# simple logger to collect summary lines for the PDF\n",
        "EDA_LOG = []\n",
        "def log(line=\"\"):\n",
        "    print(line)\n",
        "    EDA_LOG.append(str(line))\n"
      ],
      "metadata": {
        "id": "bl5fWeG3ar-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & sanity-check ROND"
      ],
      "metadata": {
        "id": "TybQGodupdo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load & concat\n",
        "rond = pd.concat([pd.read_csv(p) for p in ROND_FILES], ignore_index=True)\n",
        "\n",
        "# Basic checks\n",
        "log(\"=== ROND overview ===\")\n",
        "log(f\"Shape: {rond.shape}\")\n",
        "log(f\"Columns: {list(rond.columns)}\")\n",
        "\n",
        "expected_cols = {\"instruction\",\"input\",\"output\"}\n",
        "missing_cols = expected_cols - set(rond.columns)\n",
        "extra_cols = set(rond.columns) - expected_cols\n",
        "log(f\"Missing expected columns: {missing_cols}\")\n",
        "log(f\"Extra columns: {extra_cols}\")\n",
        "\n",
        "log(\"Nulls per column:\")\n",
        "log(rond.isnull().sum())\n",
        "\n",
        "log(f\"Duplicate rows: {rond.duplicated().sum()}\")\n"
      ],
      "metadata": {
        "id": "xmHRZ2nwaxvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROND: lengths, ratios, distributions, plots"
      ],
      "metadata": {
        "id": "zOjqtypEp1uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute token/word lengths (simple whitespace split)\n",
        "rond[\"input_len\"]  = rond[\"input\"].astype(str).str.split().str.len()\n",
        "rond[\"output_len\"] = rond[\"output\"].astype(str).str.split().str.len()\n",
        "rond[\"length_ratio\"] = rond[\"output_len\"] / rond[\"input_len\"].replace(0, np.nan)\n",
        "\n",
        "# Summary stats\n",
        "log(\"\\n=== ROND length stats ===\")\n",
        "for col in [\"input_len\",\"output_len\",\"length_ratio\"]:\n",
        "    desc = rond[col].describe(percentiles=[.1,.25,.5,.75,.9,.95]).to_string()\n",
        "    log(f\"\\n{col}:\\n{desc}\")\n",
        "\n",
        "# Histograms\n",
        "plt.figure()\n",
        "rond[\"input_len\"].clip(upper=rond[\"input_len\"].quantile(0.99)).hist(bins=40)\n",
        "plt.title(\"ROND: Input length (words)\")\n",
        "plt.xlabel(\"words\"); plt.ylabel(\"frequency\")\n",
        "plt.tight_layout(); plt.savefig(f\"{PLOT_DIR}/rond_input_len_hist.png\"); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "rond[\"output_len\"].clip(upper=rond[\"output_len\"].quantile(0.99)).hist(bins=40)\n",
        "plt.title(\"ROND: Summary length (words)\")\n",
        "plt.xlabel(\"words\"); plt.ylabel(\"frequency\")\n",
        "plt.tight_layout(); plt.savefig(f\"{PLOT_DIR}/rond_output_len_hist.png\"); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "rond[\"length_ratio\"].dropna().clip(upper=rond[\"length_ratio\"].quantile(0.99)).hist(bins=40)\n",
        "plt.title(\"ROND: summary/input length ratio\")\n",
        "plt.xlabel(\"ratio\"); plt.ylabel(\"frequency\")\n",
        "plt.tight_layout(); plt.savefig(f\"{PLOT_DIR}/rond_ratio_hist.png\"); plt.show()\n",
        "\n",
        "# Scatter (sample to keep it light)\n",
        "sample = rond.sample(min(2000, len(rond)), random_state=42)\n",
        "plt.figure()\n",
        "plt.scatter(sample[\"input_len\"], sample[\"output_len\"], s=6, alpha=0.5)\n",
        "plt.title(\"ROND: input vs summary length (sample)\")\n",
        "plt.xlabel(\"input_len\"); plt.ylabel(\"output_len\")\n",
        "plt.tight_layout(); plt.savefig(f\"{PLOT_DIR}/rond_len_scatter.png\"); plt.show()\n"
      ],
      "metadata": {
        "id": "vB0-MnH0a3Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & sanity-check BlueScrubs (clean CSVs)"
      ],
      "metadata": {
        "id": "0rOM_6QMq_p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs = pd.concat([pd.read_csv(p) for p in BLUESCRUBS_FILES], ignore_index=True)\n",
        "\n",
        "log(\"\\n=== BlueScrubs overview ===\")\n",
        "log(f\"Shape: {bs.shape}\")\n",
        "log(f\"Columns: {list(bs.columns)}\")\n",
        "\n",
        "expected_cols_bs = {\"instruction\",\"input\",\"output\"}\n",
        "missing_cols_bs = expected_cols_bs - set(bs.columns)\n",
        "extra_cols_bs = set(bs.columns) - expected_cols_bs\n",
        "log(f\"Missing expected columns: {missing_cols_bs}\")\n",
        "log(f\"Extra columns: {extra_cols_bs}\")\n",
        "\n",
        "log(\"Nulls per column:\")\n",
        "log(bs.isnull().sum())\n",
        "\n",
        "log(f\"Duplicate rows: {bs.duplicated().sum()}\")\n"
      ],
      "metadata": {
        "id": "0HRwwpxIbAmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BlueScrubs: label balance, lengths, plots"
      ],
      "metadata": {
        "id": "lQNfnG5hri_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure label is integer 0/1 (it was saved as string earlier)\n",
        "bs[\"label\"] = bs[\"output\"].astype(str).str.strip().astype(int)\n",
        "bs[\"input_len\"] = bs[\"input\"].astype(str).str.split().str.len()\n",
        "\n",
        "# Class balance\n",
        "counts = bs[\"label\"].value_counts().sort_index()\n",
        "total = len(bs)\n",
        "pos = int(counts.get(1,0)); neg = int(counts.get(0,0))\n",
        "log(\"\\n=== BlueScrubs class balance ===\")\n",
        "log(f\"0 (not cancer-related): {neg} ({neg/total:.2%})\")\n",
        "log(f\"1 (cancer-related):     {pos} ({pos/total:.2%})\")\n",
        "\n",
        "# Length stats overall & by class\n",
        "log(\"\\nBlueScrubs input length stats (overall):\")\n",
        "log(bs[\"input_len\"].describe(percentiles=[.1,.25,.5,.75,.9,.95]).to_string())\n",
        "\n",
        "log(\"\\nBlueScrubs input length stats by class:\")\n",
        "grp = bs.groupby(\"label\")[\"input_len\"].describe()\n",
        "log(grp.to_string())\n",
        "\n",
        "# Plots\n",
        "plt.figure()\n",
        "counts.plot(kind=\"bar\")\n",
        "plt.title(\"BlueScrubs: class counts (0/1)\")\n",
        "plt.xlabel(\"label\"); plt.ylabel(\"count\")\n",
        "plt.tight_layout(); plt.savefig(f\"{PLOT_DIR}/bs_label_counts.png\"); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "bs[\"input_len\"].clip(upper=bs[\"input_len\"].quantile(0.99)).hist(bins=40)\n",
        "plt.title(\"BlueScrubs: Input length (words)\")\n",
        "plt.xlabel(\"words\"); plt.ylabel(\"frequency\")\n",
        "plt.tight_layout(); plt.savefig(f\"{PLOT_DIR}/bs_input_len_hist.png\"); plt.show()\n",
        "\n",
        "plt.figure()\n",
        "bs.boxplot(column=\"input_len\", by=\"label\")\n",
        "plt.title(\"BlueScrubs: input length by class\"); plt.suptitle(\"\")\n",
        "plt.xlabel(\"label\"); plt.ylabel(\"words\")\n",
        "plt.tight_layout(); plt.savefig(f\"{PLOT_DIR}/bs_len_by_label_box.png\"); plt.show()\n"
      ],
      "metadata": {
        "id": "jjKAfKLWdD25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick data-quality flags (both datasets)"
      ],
      "metadata": {
        "id": "AbZJUi0yrs4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quality_flags(df, name, text_col=\"input\", out_col=\"output\"):\n",
        "    flags = {}\n",
        "    # blank/very short texts or outputs\n",
        "    flags[\"empty_text_rows\"] = int((df[text_col].astype(str).str.strip()==\"\").sum())\n",
        "    flags[\"very_short_text_<5w\"] = int((df[text_col].astype(str).str.split().str.len()<5).sum())\n",
        "    flags[\"empty_output_rows\"] = int((df[out_col].astype(str).str.strip()==\"\").sum())\n",
        "    # extreme lengths\n",
        "    text_len = df[text_col].astype(str).str.split().str.len()\n",
        "    flags[\"text_len_p99\"] = int(text_len.quantile(0.99))\n",
        "    flags[\"text_len_max\"] = int(text_len.max())\n",
        "    log(f\"\\n=== {name} quality flags ===\")\n",
        "    for k,v in flags.items():\n",
        "        log(f\"{k}: {v}\")\n",
        "    return flags\n",
        "\n",
        "rond_flags = quality_flags(rond, \"ROND\", \"input\", \"output\")\n",
        "bs_flags   = quality_flags(bs, \"BlueScrubs\", \"input\", \"output\")\n"
      ],
      "metadata": {
        "id": "fNaU4zium_Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the PDF report (text + charts)"
      ],
      "metadata": {
        "id": "RaYkfoSIr2qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "PDF_PATH = \"./EDA_OncoSummarizer_Report.pdf\"\n",
        "doc = SimpleDocTemplate(PDF_PATH, pagesize=letter)\n",
        "styles = getSampleStyleSheet()\n",
        "story = []\n",
        "\n",
        "story += [\n",
        "    Paragraph(\"OncoSummarizer — EDA Report\", styles[\"Title\"]),\n",
        "    Spacer(1, 12),\n",
        "    Paragraph(\"This report summarizes EDA for two datasets kept separate by task:\", styles[\"BodyText\"]),\n",
        "    Paragraph(\"• ROND (summarization) — columns: instruction, input, output\", styles[\"BodyText\"]),\n",
        "    Paragraph(\"• BlueScrubs (classification) — columns: instruction, input, output (label 0/1)\", styles[\"BodyText\"]),\n",
        "    Spacer(1, 12),\n",
        "]\n",
        "\n",
        "# Add logged text\n",
        "for line in EDA_LOG:\n",
        "    story.append(Paragraph(str(line).replace(\"\\n\",\"<br/>\"), styles[\"BodyText\"]))\n",
        "    story.append(Spacer(1, 6))\n",
        "\n",
        "# Add plots if they exist\n",
        "def add_img(path, caption):\n",
        "    if os.path.exists(path):\n",
        "        story.append(Spacer(1, 10))\n",
        "        story.append(RLImage(path, width=480, height=320))\n",
        "        story.append(Paragraph(caption, styles[\"Italic\"]))\n",
        "        story.append(Spacer(1, 10))\n",
        "\n",
        "add_img(f\"{PLOT_DIR}/rond_input_len_hist.png\", \"ROND: Input length (words)\")\n",
        "add_img(f\"{PLOT_DIR}/rond_output_len_hist.png\", \"ROND: Summary length (words)\")\n",
        "add_img(f\"{PLOT_DIR}/rond_ratio_hist.png\", \"ROND: Summary/Input length ratio\")\n",
        "add_img(f\"{PLOT_DIR}/rond_len_scatter.png\", \"ROND: Input vs Summary length (sample)\")\n",
        "\n",
        "add_img(f\"{PLOT_DIR}/bs_label_counts.png\", \"BlueScrubs: class counts (0/1)\")\n",
        "add_img(f\"{PLOT_DIR}/bs_input_len_hist.png\", \"BlueScrubs: Input length (words)\")\n",
        "add_img(f\"{PLOT_DIR}/bs_len_by_label_box.png\", \"BlueScrubs: Input length by class\")\n",
        "\n",
        "doc.build(story)\n",
        "print(f\"Saved PDF: {PDF_PATH}\")\n"
      ],
      "metadata": {
        "id": "rV-yn94pnP_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The adapted EDA code for BlueScrubs length analysis"
      ],
      "metadata": {
        "id": "wQYPUi7rBtm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ==============================\n",
        "# LOAD DATA\n",
        "# ==============================\n",
        "train_path = \"/content/bluescrubs_train_clean.csv\"\n",
        "val_path   = \"/content/bluescrubs_val_clean.csv\"\n",
        "test_path  = \"/content/bluescrubs_test_clean.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "val_df   = pd.read_csv(val_path)\n",
        "test_df  = pd.read_csv(test_path)\n",
        "\n",
        "# Combine splits\n",
        "df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "print(\"Dataset loaded.\")\n",
        "print(\"Total documents:\", len(df))\n",
        "\n",
        "# ==============================\n",
        "# WORD COUNTS\n",
        "# ==============================\n",
        "df[\"word_count\"] = df[\"input\"].astype(str).apply(lambda x: len(x.split()))\n",
        "\n",
        "# ==============================\n",
        "# BASIC STATS\n",
        "# ==============================\n",
        "print(\"\\nWord count statistics:\")\n",
        "print(df[\"word_count\"].describe(percentiles=[.5, .75, .9, .95, .99]))\n",
        "\n",
        "# ==============================\n",
        "# HISTOGRAM (log scale for long tail)\n",
        "# ==============================\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(df[\"word_count\"], bins=100, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.xlabel(\"Word Count per Document\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Document Lengths (BlueScrubs)\")\n",
        "plt.yscale(\"log\")\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# CUTOFF ANALYSIS\n",
        "# ==============================\n",
        "def pct_below(threshold):\n",
        "    return np.mean(df[\"word_count\"] <= threshold) * 100\n",
        "\n",
        "thresholds = {\n",
        "    \"BERT (512 tokens ≈ 350 words)\": 350,\n",
        "    \"Longformer (4096 tokens ≈ 3000 words)\": 3000,\n",
        "    \"Extreme cutoff (10k words)\": 10000\n",
        "}\n",
        "\n",
        "print(\"\\nPercentage of documents fitting within limits:\")\n",
        "for name, cutoff in thresholds.items():\n",
        "    print(f\"{name}: {pct_below(cutoff):.2f}%\")\n",
        "\n",
        "# ==============================\n",
        "# ZOOM IN (<5000 words)\n",
        "# ==============================\n",
        "plt.figure(figsize=(10,6))\n",
        "subset = df[df[\"word_count\"] < 5000]\n",
        "plt.hist(subset[\"word_count\"], bins=100, color=\"orange\", edgecolor=\"black\")\n",
        "plt.xlabel(\"Word Count per Document (<5000 words)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Zoomed-In Document Length Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cz1sUUIw_M4a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}